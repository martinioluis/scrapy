# scrapy / scraper

## Description:
website data recovery (ex: Zilok).

## Technologies uses:
  - Nodejs
    - express
    - tor-request
    - cheerio
  - SQL
    - mysql
  - Tor
  - Reactjs
    - react-chartjs-2
    - reactstrap
  - Python
  
The Back in Nodejs, SQL to access the data in the database, Tor to change your ip address, the Front in Reactjs to visualize the data, git and github to version my project and Python to process the data.
  
## The different steps:

### 1. / Nodejs
  - Creating a Tor request to retrieve data
  - Importing data as a JSON file
  
### 2. / Python
  - Process data in Python
  - JSON to CSV file conversion
  - Insertion of data in the Database
  
### 3. / Reactjs
  - Data visualization
  
## Images:
![alt text](https://res.cloudinary.com/dsxb2uyct/image/upload/v1583834190/table_cdqgyd.png "table chart")
![alt text](https://res.cloudinary.com/dsxb2uyct/image/upload/v1583834190/bar_chart_qcimn3.png "bar chart")
![alt text](https://res.cloudinary.com/dsxb2uyct/image/upload/v1583834190/pie_chart_xvppsc.png "pie chart")
  
## Conclusion:
I was delighted to work on this project because I had to project myself on different ways of a web application. This little application was for me a complete way to see the different aspects of a website. The beginning of the project was tedious because I had to look for solutions that had nothing to do with the code but with my computer (Mac). The sequel was very enriching from a technical point of view. Overall, I came out of it with new tools in hand that will help me progress in my evolution as a developer.

## contributor:
[Martin Peubey](https://github.com/martinioluis)
